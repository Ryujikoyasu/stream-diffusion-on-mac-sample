from typing import Literal
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch

from .utils import StreamDiffusionWrapper
from config import config


class StreamDiffusion:
    def __init__(
        self,
        model_id_or_path: str = None,
        prompt: str = "moon",
        negative_prompt: str = "human, person, people, face, portrait, girl, boy, man, woman, child, body, hands, fingers, nsfw, figure, silhouette, shadow person, character, anime character, manga, anime style, humanoid, anthropomorphic, human-like, human shape, facial features, eyes, mouth, nose, hair, clothing, dress, outfit, costume,standing figure, walking figure, sitting figure,1girl, 2girls, multiple girls, multiple people,human elements, human presence, human form".replace('\n', '').replace(' ', ''),
        acceleration: Literal["none", "xformers", "tensorrt"] = "none",
        use_denoising_batch: bool = True,
        use_tiny_vae: bool = True,
        guidance_scale: float = None,
        delta: float = None,
        local_cache_dir: str = None,
        # refç‰ˆã®è¨­å®šã‚’è¿½åŠ ï¼ˆäº’æ›æ€§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        optimize_for_speed: bool = None,
        use_kohaku_model: bool = None,
    ) -> None:
        self.prompt = prompt
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å–å¾—
        if model_id_or_path is None:
            model_id_or_path = config.model_id
        if guidance_scale is None:
            guidance_scale = config.guidance_scale
        if delta is None:
            delta = config.delta
        if local_cache_dir is None:
            local_cache_dir = config.models_dir
        if optimize_for_speed is None:
            optimize_for_speed = config.get('streamdiffusion.optimize_for_speed', True)
        if use_kohaku_model is None:
            use_kohaku_model = config.get('streamdiffusion.use_kohaku_model', False)
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆStreamDiffusionã®CUDAã‚¤ãƒ™ãƒ³ãƒˆå•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚CPUã‚’ä½¿ç”¨ï¼‰
        # TODO: MPSã‚µãƒãƒ¼ãƒˆã®ãŸã‚ã«StreamDiffusionãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¿®æ­£ãŒå¿…è¦
        self.device = torch.device("mps")
        print("ğŸ–¥ï¸ Using CPU (MPS has compatibility issues with StreamDiffusion)")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆrefç‰ˆã®èŠ¸è¡“ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ï¼‰
        if use_kohaku_model:
            model_id_or_path = "KBlueLeaf/kohaku-v2.1"
            print("ğŸ¨ Using Kohaku artistic model")
        
        # é€Ÿåº¦æœ€é©åŒ–è¨­å®š
        if optimize_for_speed:
            t_index_list = [8]
            warmup = 1
            num_inference_steps = 16
            print("âš¡ Speed optimization enabled")
        else:
            t_index_list = [8]
            warmup = 10
            num_inference_steps = 16
        
        try:
            # StreamDiffusionWrapper expects device string, convert from device object
            if self.device.type == "cuda":
                device_str = "cuda"
            elif self.device.type == "mps":
                device_str = "mps"
            else:
                device_str = "cpu"
            
            self.stream = StreamDiffusionWrapper(
                model_id_or_path=model_id_or_path,
                t_index_list=t_index_list,
                warmup=warmup,
                device=device_str,
                acceleration=acceleration,
                mode="img2img",
                use_denoising_batch=use_denoising_batch,
                use_tiny_vae=use_tiny_vae,
                cfg_type="none" if optimize_for_speed else ("self" if guidance_scale > 1.0 else "none"),
                seed=-1 if config.use_random_seed else 2,  # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š
                local_cache_dir=local_cache_dir,
            )
            
            # CPUä½¿ç”¨æ™‚ã¯float32ã®ã¾ã¾ï¼ˆhalf precisionã¯CPUã§æœªã‚µãƒãƒ¼ãƒˆï¼‰
            print("ğŸ”§ Using float32 precision for CPU compatibility")
            
            self.stream.prepare(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                delta=delta,
            )
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _initialize_stream(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å†åˆæœŸåŒ–ï¼ˆrefç‰ˆã‹ã‚‰ã®è¿½åŠ æ©Ÿèƒ½ï¼‰"""
        if self.stream is not None and self.device.type == "mps":
            torch.mps.empty_cache()
            # å€‹åˆ¥ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å¯¾ã—ã¦halfç²¾åº¦ã‚’é©ç”¨
            if hasattr(self.stream, 'unet'):
                self.stream.unet = self.stream.unet.half()
            if hasattr(self.stream, 'vae'):
                self.stream.vae = self.stream.vae.half()
            print("ğŸ”„ Stream reinitialized with optimizations")
        return self.stream
