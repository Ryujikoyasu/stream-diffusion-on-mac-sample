from typing import Literal

import torch

from .utils import StreamDiffusionWrapper


class StreamDiffusion:
    def __init__(
        self,
        model_id_or_path: str = "stabilityai/sd-turbo",
        prompt: str = "moon",
        negative_prompt: str = "human, person, people, face, portrait, girl, boy, man, woman, child, body, hands, fingers, nsfw, figure, silhouette, shadow person, character, anime character, manga, anime style, humanoid, anthropomorphic, human-like, human shape, facial features, eyes, mouth, nose, hair, clothing, dress, outfit, costume,standing figure, walking figure, sitting figure,1girl, 2girls, multiple girls, multiple people,human elements, human presence, human form".replace('\n', '').replace(' ', ''),
        acceleration: Literal["none", "xformers", "tensorrt"] = "none",
        use_denoising_batch: bool = True,
        use_tiny_vae: bool = True,
        guidance_scale: float = 0.6,
        delta: float = 1.5,
        local_cache_dir: str = "./models",
        # refç‰ˆã®è¨­å®šã‚’è¿½åŠ ï¼ˆäº’æ›æ€§ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        optimize_for_speed: bool = True,
        use_kohaku_model: bool = False,
    ) -> None:
        self.prompt = prompt
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆStreamDiffusionã®CUDAã‚¤ãƒ™ãƒ³ãƒˆå•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚CPUã‚’ä½¿ç”¨ï¼‰
        # TODO: MPSã‚µãƒãƒ¼ãƒˆã®ãŸã‚ã«StreamDiffusionãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ä¿®æ­£ãŒå¿…è¦
        self.device = torch.device("mps")
        print("ğŸ–¥ï¸ Using CPU (MPS has compatibility issues with StreamDiffusion)")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆrefç‰ˆã®èŠ¸è¡“ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ï¼‰
        if use_kohaku_model:
            model_id_or_path = "KBlueLeaf/kohaku-v2.1"
            print("ğŸ¨ Using Kohaku artistic model")
        
        # é€Ÿåº¦æœ€é©åŒ–è¨­å®š
        if optimize_for_speed:
            t_index_list = [8]
            warmup = 1
            num_inference_steps = 16
            print("âš¡ Speed optimization enabled")
        else:
            t_index_list = [8]
            warmup = 10
            num_inference_steps = 16
        
        try:
            # StreamDiffusionWrapper expects device string, convert from device object
            if self.device.type == "cuda":
                device_str = "cuda"
            elif self.device.type == "mps":
                device_str = "mps"
            else:
                device_str = "cpu"
            
            self.stream = StreamDiffusionWrapper(
                model_id_or_path=model_id_or_path,
                t_index_list=t_index_list,
                warmup=warmup,
                device=device_str,
                acceleration=acceleration,
                mode="img2img",
                use_denoising_batch=use_denoising_batch,
                use_tiny_vae=use_tiny_vae,
                cfg_type="none" if optimize_for_speed else ("self" if guidance_scale > 1.0 else "none"),
                seed=-1,  # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–
                local_cache_dir=local_cache_dir,
            )
            
            # CPUä½¿ç”¨æ™‚ã¯float32ã®ã¾ã¾ï¼ˆhalf precisionã¯CPUã§æœªã‚µãƒãƒ¼ãƒˆï¼‰
            print("ğŸ”§ Using float32 precision for CPU compatibility")
            
            self.stream.prepare(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                delta=delta,
            )
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _initialize_stream(self):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å†åˆæœŸåŒ–ï¼ˆrefç‰ˆã‹ã‚‰ã®è¿½åŠ æ©Ÿèƒ½ï¼‰"""
        if self.stream is not None and self.device.type == "mps":
            torch.mps.empty_cache()
            # å€‹åˆ¥ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å¯¾ã—ã¦halfç²¾åº¦ã‚’é©ç”¨
            if hasattr(self.stream, 'unet'):
                self.stream.unet = self.stream.unet.half()
            if hasattr(self.stream, 'vae'):
                self.stream.vae = self.stream.vae.half()
            print("ğŸ”„ Stream reinitialized with optimizations")
        return self.stream
